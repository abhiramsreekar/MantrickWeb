{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(type(digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(digits.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "print(type(digits.data))\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(64,)\n",
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(type(digits.data[0]))\n",
    "print(digits.data[0].shape)\n",
    "print(digits.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(1, 5):\n",
    "    plt.subplot(2,2, i)\n",
    "    plt.imshow(digits.data[i].reshape(8, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "print(digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347, 64) (1347,) (450, 64) (450,)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, digits.target, test_size= 0.25 )\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "done in %0.3fs 8.623350143432617\n"
     ]
    }
   ],
   "source": [
    "# Train a SVM classification model\n",
    "from time import time\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#clf = SVC(C= 1, gamma = 0.1, verbose=True, kernel='rbf')\n",
    "#Tuning: Model selection\n",
    "param_grid = {\n",
    "               'C': [1e-3, 1e-2, 1, 1e2, 1e3],\n",
    "              'gamma': [0.0001, 0.001, 0.1, 1], \n",
    "               'kernel': ['linear', 'rbf'],\n",
    "             }\n",
    "\n",
    "clf = GridSearchCV( SVC(), param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"done in %0.3fs\" , (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9911111111111112\n",
      "Best parameters selected from Grid search {'C': 100.0, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_test, y_test))\n",
    "print(\"Best parameters selected from Grid search\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of support vectors (672,)\n",
      "Dual coeffecients (9, 672)\n"
     ]
    }
   ],
   "source": [
    "print(\"Indices of support vectors\", clf.best_estimator_.support_.shape)\n",
    "print(\"Dual coeffecients\", clf.best_estimator_.dual_coef_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of support vectors per each class: [38 78 61 71 67 66 50 70 89 82]\n",
      "\n",
      "Indices of support vectors [  12   53  131  146  184  185  221  311  344  355  393  500  505  512\n",
      "  530  640  651  673  681  719  743  746  776  796  822  919  928  938\n",
      "  939  942  999 1026 1165 1188 1206 1219 1269 1333    2   75   76  108\n",
      "  112  116  147  179  183  207  211  220  223  227  262  266  267  279\n",
      "  288  297  303  307  312  346  349  388  395  449  459  489  490  496\n",
      "  499  504  571  646  686  698  702  703  718  731  736  740  782  828\n",
      "  835  870  880  886  918  935  944  961  989  990 1006 1019 1027 1055\n",
      " 1065 1067 1090 1112 1119 1124 1159 1173 1193 1236 1250 1253 1264 1292\n",
      " 1295 1316 1320 1334   13   25   63  181  195  209  240  261  277  323\n",
      "  324  364  373  412  433  461  466  468  478  480  484  493  579  596\n",
      "  600  610  633  654  678  693  730  767  772  775  780  824  826  836\n",
      "  839  883  884  929  958  992 1020 1024 1054 1059 1073 1078 1101 1133\n",
      " 1194 1195 1215 1231 1277 1314 1327 1336 1340   16   21   54   72   80\n",
      "   91  127  133  140  143  186  187  188  196  212  224  228  253  270\n",
      "  308  313  361  375  396  397  425  446  492  511  523  528  543  548\n",
      "  589  616  617  620  667  728  735  785  789  792  800  841  842  862\n",
      "  885  914  933  937  951  957  966 1001 1007 1008 1056 1083 1130 1144\n",
      " 1228 1230 1233 1256 1260 1276 1282 1307 1337 1346   19   26   36   41\n",
      "   66   77  122  153  160  166  173  251  272  286  334  399  439  444\n",
      "  452  481  522  544  546  547  588  594  595  613  628  636  656  674\n",
      "  677  680  700  714  723  733  745  753  783  827  863  891  899  905\n",
      "  927  930  974 1015 1042 1070 1080 1095 1137 1140 1152 1155 1162 1170\n",
      " 1196 1199 1226 1240 1281 1319 1339    3   10   43   79  102  158  203\n",
      "  208  210  219  234  239  256  260  275  283  296  316  333  420  423\n",
      "  434  447  464  471  472  565  592  645  653  659  661  665  739  750\n",
      "  751  769  770  786  794  798  803  819  851  924  955  982 1033 1041\n",
      " 1089 1121 1125 1142 1163 1202 1213 1217 1218 1224 1252 1254 1270 1293\n",
      " 1297 1305 1342   90   97  128  171  193  198  199  216  232  252  255\n",
      "  268  294  317  331  341  370  408  411  428  527  537  554  564  668\n",
      "  742  757  760  784  787  845  850  897 1040 1057 1060 1126 1138 1167\n",
      " 1176 1203 1209 1210 1243 1267 1301 1315 1322 1328 1338    1   14   30\n",
      "   44   55   81  109  117  157  178  233  236  237  245  281  309  310\n",
      "  327  332  357  371  410  414  415  417  421  430  520  541  558  570\n",
      "  578  599  608  664  679  694  704  716  720  754  763  771  790  811\n",
      "  817  823  855  874  876  896  906  910  971  983 1000 1003 1025 1081\n",
      " 1094 1118 1131 1134 1146 1234 1248 1257 1275 1302 1325   78  114  126\n",
      "  134  148  149  159  164  169  189  226  231  238  243  259  263  274\n",
      "  322  328  336  378  380  392  394  419  436  455  458  467  486  517\n",
      "  518  532  536  556  580  586  622  625  626  627  634  643  655  657\n",
      "  684  705  722  724  729  762  766  773  815  852  853  857  867  869\n",
      "  892  895  900  903  913  917  920  959  968  972  973  979  995 1011\n",
      " 1029 1050 1053 1068 1077 1104 1143 1154 1156 1160 1168 1178 1181 1284\n",
      " 1298 1318   22   31   33   46   52   61   62   83   95   98  104  150\n",
      "  200  222  290  345  377  384  387  407  431  440  445  454  470  474\n",
      "  476  482  485  488  498  507  552  553  562  563  568  584  606  607\n",
      "  614  638  650  691  711  741  744  761  768  802  821  825  829  843\n",
      "  859  898  923  925  948  975  976  985 1035 1039 1052 1093 1102 1113\n",
      " 1127 1183 1190 1211 1239 1247 1259 1262 1263 1268 1280 1290 1324 1343]\n",
      "\n",
      "Dual coeffecients [ 9.89249609e-02  3.27263977e-01  7.26585802e-01  6.75262242e-01\n",
      "  2.24658581e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  3.65710482e-01  0.00000000e+00  8.06142156e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.28513586e-01\n",
      "  1.04303163e-01  1.24054900e-01  2.45014394e-01  3.97803153e-01\n",
      "  1.92376687e-02  0.00000000e+00  2.08025922e-01  7.33146034e-02\n",
      "  2.55586886e-01  0.00000000e+00  3.93597679e-01  9.17714216e-02\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  4.66500412e-01  7.55803127e-02\n",
      "  3.24943484e-01  1.30780415e-02 -1.10214115e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -9.12176652e-03\n",
      " -1.30332758e-01 -0.00000000e+00 -0.00000000e+00 -1.65831136e-01\n",
      " -1.58859057e-01 -7.97039169e-02 -2.04119034e-01 -6.59414313e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -3.24905315e-01 -2.55248811e-01 -1.06008033e-01\n",
      " -0.00000000e+00 -2.27795963e-01 -1.75293783e-01 -2.17516572e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -5.99776569e-01 -0.00000000e+00\n",
      " -3.08628073e-01 -0.00000000e+00 -3.02619489e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -8.44753576e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -4.74531424e-01 -1.41774763e-02 -2.82515251e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -7.16002676e-02 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -2.07961869e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -1.31996158e-01 -0.00000000e+00 -3.18063860e-01 -1.52491709e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -1.20716583e-01 -2.00711133e-03\n",
      " -0.00000000e+00 -1.44729110e-01 -0.00000000e+00 -3.31237757e-01\n",
      " -0.00000000e+00 -1.79911710e-02 -2.56582730e-01 -2.53960328e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -1.93183569e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -3.41923441e-02 -0.00000000e+00 -2.64678223e-02\n",
      " -9.23675793e-03 -3.68292407e-01 -8.02338401e-02 -4.51659566e-01\n",
      " -2.77667898e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -6.84102758e-02 -0.00000000e+00 -0.00000000e+00 -2.58179311e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -3.53584376e-01 -6.75128059e-01\n",
      " -0.00000000e+00 -1.05125166e-01 -0.00000000e+00 -1.43401959e-02\n",
      " -2.07212960e-01 -1.00162355e-02 -5.64992401e-02 -1.04402188e+00\n",
      " -1.91407045e-02 -0.00000000e+00 -1.35391690e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -2.71045356e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -7.36110557e-02 -3.65831965e-01 -2.25631999e-01\n",
      " -1.76486723e-01 -3.48154068e-01 -3.89448202e-01 -1.36838078e-01\n",
      " -6.54204305e-02 -3.73077148e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -6.79064413e-02 -0.00000000e+00 -1.19195393e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -1.27779315e-01 -5.56105576e-02 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -2.65120169e-01 -2.05742746e-01\n",
      " -0.00000000e+00 -9.45149815e-03 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.42657776e-01\n",
      " -4.79479754e-01 -0.00000000e+00 -4.47756454e-01 -2.75686746e-01\n",
      " -1.05429696e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -4.65448494e-01 -0.00000000e+00 -0.00000000e+00 -1.15694322e-01\n",
      " -0.00000000e+00 -3.94043623e-02 -3.63770143e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -2.52676156e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -1.42640446e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -1.12557177e-01 -4.12687762e-02 -2.28456182e-02\n",
      " -0.00000000e+00 -4.79901149e-01 -1.08844915e-01 -4.51880461e-01\n",
      " -0.00000000e+00 -9.34360507e-02 -0.00000000e+00 -0.00000000e+00\n",
      " -4.00256488e-01 -0.00000000e+00 -1.21212422e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -1.10246931e-01 -0.00000000e+00 -5.07852232e-01\n",
      " -4.46252180e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -2.10291202e-01 -1.86727188e-01 -7.80026075e-02 -0.00000000e+00\n",
      " -6.81614427e-02 -0.00000000e+00 -4.69248384e-01 -0.00000000e+00\n",
      " -1.70923234e-01 -1.07767209e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -6.13104116e-02 -0.00000000e+00 -5.74191789e-01 -1.03240067e-02\n",
      " -1.18669843e-01 -3.50276556e-01 -6.85283349e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -4.47150720e-02 -0.00000000e+00 -6.10783340e-02\n",
      " -0.00000000e+00 -3.38409993e-02 -4.79031118e-01 -3.61206975e-02\n",
      " -3.08436166e-01 -0.00000000e+00 -8.04540317e-02 -1.09790296e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -6.03084282e-01 -6.72956321e-02\n",
      " -1.81470040e-01 -0.00000000e+00 -0.00000000e+00 -2.67705585e-01\n",
      " -0.00000000e+00 -2.66031671e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -2.69631453e-01 -1.22125127e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -1.30867056e-01 -0.00000000e+00 -2.22386801e-01\n",
      " -3.77372010e-02 -0.00000000e+00 -7.83576388e-01 -9.09331989e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -8.51912419e-02 -4.00835592e-01 -6.74082371e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -1.08379063e-01\n",
      " -1.69822144e-01 -2.25211424e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -8.89550451e-02 -0.00000000e+00 -0.00000000e+00 -4.15703574e-01\n",
      " -0.00000000e+00 -1.75748431e-02 -0.00000000e+00 -2.90727047e-01\n",
      " -1.18983181e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -2.55619378e-01 -1.05586996e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -5.86001816e-01\n",
      " -9.88841575e-02 -6.47954585e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -4.64828519e-01 -2.72589226e-01 -0.00000000e+00 -1.16374418e-01\n",
      " -1.50003711e-02 -3.75379717e-01 -3.48685936e-01 -6.36631820e-03\n",
      " -0.00000000e+00 -0.00000000e+00 -1.05377986e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -1.03893697e-01 -0.00000000e+00 -4.57548214e-01\n",
      " -3.91855732e-02 -2.58564182e-01 -3.73412110e-02 -2.96123628e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -1.04171060e-01 -7.60872753e-01\n",
      " -4.45680353e-01 -5.16662354e-03 -0.00000000e+00 -2.04182260e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -1.71183314e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -8.47946777e-01 -0.00000000e+00\n",
      " -2.34706619e-01 -1.92399317e-01 -4.11820996e-01 -5.54867575e-02\n",
      " -0.00000000e+00 -1.07971484e+00 -2.36824165e-01 -2.27111425e-03\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -1.46368459e-01 -4.17479646e-01 -9.31603361e-02 -0.00000000e+00\n",
      " -3.47551102e-01 -5.75454203e-01 -8.52508603e-01 -0.00000000e+00\n",
      " -7.72744934e-02 -0.00000000e+00 -2.26722559e-01 -0.00000000e+00\n",
      " -1.11122865e-01 -0.00000000e+00 -0.00000000e+00 -4.25832713e-01\n",
      " -6.67408906e-01 -0.00000000e+00 -2.34823000e-02 -2.30146651e-02\n",
      " -1.33742126e-01 -1.99056914e-01 -9.64495758e-03 -0.00000000e+00\n",
      " -5.97188876e-02 -7.32238270e-02 -0.00000000e+00 -1.12661830e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -3.90643200e-01\n",
      " -1.77687453e-01 -0.00000000e+00 -1.72838272e-01 -8.03600603e-02\n",
      " -0.00000000e+00 -1.11782292e+00 -0.00000000e+00 -2.02039827e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -2.55842760e-01 -0.00000000e+00\n",
      " -2.62411479e-01 -0.00000000e+00 -2.06330252e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -4.09296660e-02 -0.00000000e+00 -1.94864127e-01\n",
      " -1.43214901e-01 -0.00000000e+00 -7.29605124e-02 -4.65845654e-01\n",
      " -2.33833540e-01 -0.00000000e+00 -0.00000000e+00 -6.79652594e-01\n",
      " -4.59350567e-03 -1.37804723e-01 -0.00000000e+00 -3.07392241e-02\n",
      " -2.23020626e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -2.41780418e-01 -4.71335109e-01 -4.13256309e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -1.41199280e-01 -9.09248467e-04 -9.22396326e-02 -4.14659289e-02\n",
      " -7.21906522e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -3.55805338e-01\n",
      " -0.00000000e+00 -4.54984791e-02 -1.74524081e-01 -3.43083739e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -2.34304262e-01 -1.62309694e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -1.51842022e-01 -6.71713385e-03\n",
      " -0.00000000e+00 -7.24679180e-02 -0.00000000e+00 -4.72322478e-02\n",
      " -2.51735796e-01 -7.69282588e-02 -0.00000000e+00 -1.66870142e-01\n",
      " -2.83274605e-01 -0.00000000e+00 -0.00000000e+00 -4.25850095e-02\n",
      " -0.00000000e+00 -1.85584303e-01 -1.18497436e-01 -7.08584378e-02\n",
      " -7.56252079e-02 -0.00000000e+00 -8.75103250e-02 -0.00000000e+00\n",
      " -0.00000000e+00 -1.00258444e-01 -1.68431920e-01 -4.53541809e-02\n",
      " -1.58911941e-01 -1.12040544e-01 -1.78759160e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -7.40815407e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -1.04868841e-01 -0.00000000e+00 -0.00000000e+00 -6.52842993e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -5.20765516e-02 -2.37223321e-02 -6.82380063e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -3.73963763e-01\n",
      " -1.59780862e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -9.30100639e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -9.44581591e-02 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -1.04602414e-01 -0.00000000e+00 -4.58226217e-01 -0.00000000e+00\n",
      " -2.13194232e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -6.00245428e-01 -0.00000000e+00 -6.82604256e-01 -7.55997554e-02\n",
      " -0.00000000e+00 -9.78542251e-01 -2.82149279e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -5.07542421e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -4.57901192e-02 -0.00000000e+00 -1.32485326e-02 -2.63916410e-01\n",
      " -0.00000000e+00 -3.66764864e-02 -8.48779117e-01 -2.17822982e-01\n",
      " -4.34816998e-01 -1.81918553e-02 -2.38391424e-02 -0.00000000e+00\n",
      " -8.16861316e-03 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -2.97914936e-02 -4.66790061e-01 -1.19308834e-01 -0.00000000e+00\n",
      " -2.51902219e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -2.95072006e-01 -1.87996233e-01 -0.00000000e+00\n",
      " -2.02374594e-01 -0.00000000e+00 -3.62062689e-02 -4.61114904e-01\n",
      " -4.04876442e-02 -4.84227318e-01 -0.00000000e+00 -2.42259621e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -1.91738372e-01 -0.00000000e+00\n",
      " -2.40870099e-01 -1.32406683e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -1.61491525e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -2.59506282e-02 -8.07985084e-02\n",
      " -0.00000000e+00 -5.87605118e-01 -0.00000000e+00 -7.20564129e-01\n",
      " -7.84502388e-02 -6.17120345e-01 -0.00000000e+00 -7.64511079e-02\n",
      " -7.05938569e-04 -2.64458985e-01 -1.23069470e-01 -5.74215069e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.87150939e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -2.80338628e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -8.49502322e-02 -0.00000000e+00 -1.89428977e-01 -1.83564025e-01\n",
      " -0.00000000e+00 -2.40247318e-02 -2.84607165e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -3.79031453e-02]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of support vectors per each class:\", clf.best_estimator_.n_support_ )\n",
    "print(\"\\nIndices of support vectors\", clf.best_estimator_.support_)\n",
    "print(\"\\nDual coeffecients\", clf.best_estimator_.dual_coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.01477795, 0.06567502, 0.0077621 , 0.07477717, 0.01606207,\n",
       "        0.06470909, 0.01521993, 0.1150526 , 0.01250744, 0.07181625,\n",
       "        0.01260567, 0.06625147, 0.00801501, 0.07406278, 0.0043345 ,\n",
       "        0.10406852, 0.0102941 , 0.02206502, 0.01157694, 0.02632251,\n",
       "        0.00947852, 0.08176498, 0.01099286, 0.11524401, 0.00662341,\n",
       "        0.00985193, 0.00977635, 0.02475438, 0.00945354, 0.08789077,\n",
       "        0.00945387, 0.11556273]),\n",
       " 'std_fit_time': array([0.00434574, 0.00698574, 0.00699075, 0.00847793, 0.00482718,\n",
       "        0.00721234, 0.00279362, 0.00410268, 0.00625374, 0.00648459,\n",
       "        0.00630528, 0.00417127, 0.00678825, 0.00602187, 0.00611117,\n",
       "        0.00794285, 0.0067036 , 0.00788524, 0.00622686, 0.00579785,\n",
       "        0.00794175, 0.00624702, 0.00623329, 0.0050721 , 0.00609747,\n",
       "        0.00627832, 0.00801585, 0.0074845 , 0.00772005, 0.00765427,\n",
       "        0.00799862, 0.00700927]),\n",
       " 'mean_score_time': array([0.        , 0.02592683, 0.00797062, 0.01761022, 0.00079188,\n",
       "        0.025247  , 0.00109396, 0.02294984, 0.00312696, 0.02304182,\n",
       "        0.        , 0.02883124, 0.00492268, 0.02158213, 0.00513697,\n",
       "        0.03103852, 0.00230961, 0.01607299, 0.00192995, 0.010076  ,\n",
       "        0.00312529, 0.02187781, 0.00386124, 0.03106833, 0.00352607,\n",
       "        0.01075325, 0.00312495, 0.012501  , 0.00312495, 0.01874986,\n",
       "        0.00624995, 0.03282814]),\n",
       " 'std_score_time': array([0.        , 0.00857841, 0.00700551, 0.00701896, 0.00158377,\n",
       "        0.00583789, 0.00152527, 0.00611802, 0.00625391, 0.00478408,\n",
       "        0.        , 0.00598522, 0.00604014, 0.00729805, 0.00653513,\n",
       "        0.00068521, 0.00461922, 0.00087182, 0.00260344, 0.00687015,\n",
       "        0.00625057, 0.00765479, 0.00483735, 0.00107133, 0.00610199,\n",
       "        0.00768882, 0.0062499 , 0.0062505 , 0.0062499 , 0.00625007,\n",
       "        0.0076546 , 0.00208074]),\n",
       " 'param_C': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 100.0, 100.0, 100.0, 100.0, 100.0,\n",
       "                    100.0, 100.0, 100.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.1, 0.1, 1, 1, 0.0001,\n",
       "                    0.0001, 0.001, 0.001, 0.1, 0.1, 1, 1, 0.0001, 0.0001,\n",
       "                    0.001, 0.001, 0.1, 0.1, 1, 1, 0.0001, 0.0001, 0.001,\n",
       "                    0.001, 0.1, 0.1, 1, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.001, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 0.001, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 0.001, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 0.001, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.001, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 0.001, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 0.001, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 0.001, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 100.0, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 100.0, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 100.0, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 100.0, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 100.0, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 100.0, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 100.0, 'gamma': 1, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.98518519, 0.11111111, 0.98518519, 0.11111111, 0.98518519,\n",
       "        0.11111111, 0.98518519, 0.11111111, 0.98518519, 0.11111111,\n",
       "        0.98518519, 0.11111111, 0.98518519, 0.11111111, 0.98518519,\n",
       "        0.11111111, 0.98148148, 0.97037037, 0.98148148, 0.99259259,\n",
       "        0.98148148, 0.11111111, 0.98148148, 0.11111111, 0.98148148,\n",
       "        0.98888889, 0.98148148, 0.99259259, 0.98148148, 0.11111111,\n",
       "        0.98148148, 0.11111111]),\n",
       " 'split1_test_score': array([0.97037037, 0.11111111, 0.97037037, 0.11111111, 0.97037037,\n",
       "        0.11111111, 0.97037037, 0.11111111, 0.98518519, 0.11111111,\n",
       "        0.98518519, 0.11111111, 0.98518519, 0.11111111, 0.98518519,\n",
       "        0.11111111, 0.98518519, 0.95185185, 0.98518519, 0.98888889,\n",
       "        0.98518519, 0.11111111, 0.98518519, 0.11111111, 0.98518519,\n",
       "        0.98518519, 0.98518519, 0.99259259, 0.98518519, 0.11111111,\n",
       "        0.98518519, 0.11111111]),\n",
       " 'split2_test_score': array([0.97026022, 0.10780669, 0.97026022, 0.10780669, 0.97026022,\n",
       "        0.10780669, 0.97026022, 0.10780669, 0.9739777 , 0.10780669,\n",
       "        0.9739777 , 0.10780669, 0.9739777 , 0.10780669, 0.9739777 ,\n",
       "        0.10780669, 0.9739777 , 0.96654275, 0.9739777 , 0.98141264,\n",
       "        0.9739777 , 0.10780669, 0.9739777 , 0.10780669, 0.9739777 ,\n",
       "        0.9739777 , 0.9739777 , 0.98141264, 0.9739777 , 0.10780669,\n",
       "        0.9739777 , 0.10780669]),\n",
       " 'split3_test_score': array([0.98141264, 0.11152416, 0.98141264, 0.11152416, 0.98141264,\n",
       "        0.11152416, 0.98141264, 0.11152416, 0.98141264, 0.11152416,\n",
       "        0.98141264, 0.11152416, 0.98141264, 0.11152416, 0.98141264,\n",
       "        0.11152416, 0.98141264, 0.9739777 , 0.98141264, 0.98513011,\n",
       "        0.98141264, 0.11152416, 0.98141264, 0.11152416, 0.98141264,\n",
       "        0.98884758, 0.98141264, 0.98884758, 0.98141264, 0.11152416,\n",
       "        0.98141264, 0.11152416]),\n",
       " 'split4_test_score': array([0.9739777 , 0.11152416, 0.9739777 , 0.11152416, 0.9739777 ,\n",
       "        0.11152416, 0.9739777 , 0.11152416, 0.97769517, 0.11152416,\n",
       "        0.97769517, 0.11152416, 0.97769517, 0.11152416, 0.97769517,\n",
       "        0.11152416, 0.98513011, 0.9739777 , 0.98513011, 0.99628253,\n",
       "        0.98513011, 0.11152416, 0.98513011, 0.11152416, 0.98513011,\n",
       "        0.98513011, 0.98513011, 0.99628253, 0.98513011, 0.11152416,\n",
       "        0.98513011, 0.11152416]),\n",
       " 'mean_test_score': array([0.97624122, 0.11061545, 0.97624122, 0.11061545, 0.97624122,\n",
       "        0.11061545, 0.97624122, 0.11061545, 0.98069117, 0.11061545,\n",
       "        0.98069117, 0.11061545, 0.98069117, 0.11061545, 0.98069117,\n",
       "        0.11061545, 0.98143742, 0.96734407, 0.98143742, 0.98886135,\n",
       "        0.98143742, 0.11061545, 0.98143742, 0.11061545, 0.98143742,\n",
       "        0.98440589, 0.98143742, 0.99034559, 0.98143742, 0.11061545,\n",
       "        0.98143742, 0.11061545]),\n",
       " 'std_test_score': array([0.00603491, 0.00141647, 0.00603491, 0.00141647, 0.00603491,\n",
       "        0.00141647, 0.00603491, 0.00141647, 0.00435797, 0.00141647,\n",
       "        0.00435797, 0.00141647, 0.00435797, 0.00141647, 0.00435797,\n",
       "        0.00141647, 0.00408244, 0.00821972, 0.00408244, 0.00526122,\n",
       "        0.00408244, 0.00141647, 0.00408244, 0.00141647, 0.00408244,\n",
       "        0.00547184, 0.00408244, 0.00504751, 0.00408244, 0.00141647,\n",
       "        0.00408244, 0.00141647]),\n",
       " 'rank_test_score': array([16, 21, 16, 21, 16, 21, 16, 21, 12, 21, 12, 21, 12, 21, 12, 21,  4,\n",
       "        20,  4,  2,  4, 21,  4, 21,  4,  3,  4,  1,  4, 21,  4, 21])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression score: 0.955556\n",
      "done in %0.3fs 2.1793177127838135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors, linear_model\n",
    "logistic = linear_model.LogisticRegression(solver='lbfgs', max_iter=7000,\n",
    "                                           multi_class='multinomial', verbose=2)\n",
    "\n",
    "t0 = time()\n",
    "print('LogisticRegression score: %f'\n",
    "      % logistic.fit(X_train, y_train).score(X_test, y_test))\n",
    "print(\"done in %0.3fs\" , (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on GridSearchCV in module sklearn.model_selection._search object:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |  \n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
      " |  \"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
      " |  implemented in the estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object.\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (`str`) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : str, callable, list, tuple or dict, default=None\n",
      " |      Strategy to evaluate the performance of the cross-validated model on\n",
      " |      the test set.\n",
      " |  \n",
      " |      If `scoring` represents a single score, one can use:\n",
      " |  \n",
      " |      - a single string (see :ref:`scoring_parameter`);\n",
      " |      - a callable (see :ref:`scoring`) that returns a single value.\n",
      " |  \n",
      " |      If `scoring` represents multiple scores, one can use:\n",
      " |  \n",
      " |      - a list or tuple of unique strings;\n",
      " |      - a callable returning a dictionary where the keys are the metric\n",
      " |        names and the values are the metric scores;\n",
      " |      - a dictionary with metric names as keys and callables a values.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionchanged:: v0.20\n",
      " |         `n_jobs` default changed from 1 to None\n",
      " |  \n",
      " |  refit : bool, str, or callable, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      " |      scorer that would be used to find the best parameters for refitting\n",
      " |      the estimator at the end.\n",
      " |  \n",
      " |      Where there are considerations other than maximum score in\n",
      " |      choosing a best estimator, ``refit`` can be set to a function which\n",
      " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      " |      according to the returned ``best_index_`` while the ``best_score_``\n",
      " |      attribute will not be available.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``GridSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Support for callable added.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, default=None\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 5-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used. These splitters are instantiated\n",
      " |      with `shuffle=False` so the splits will be the same across calls.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  verbose : int\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |      - >1 : the computation time for each fold and parameter candidate is\n",
      " |        displayed;\n",
      " |      - >2 : the score is also displayed;\n",
      " |      - >3 : the fold and candidate parameter indexes are also displayed\n",
      " |        together with the starting time of the computation.\n",
      " |  \n",
      " |  pre_dispatch : int, or str, default=n_jobs\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A str, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  error_score : 'raise' or numeric, default=np.nan\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : bool, default=False\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |      .. versionchanged:: 0.21\n",
      " |          Default value was changed from ``True`` to ``False``\n",
      " |  \n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svc = svm.SVC()\n",
      " |  >>> clf = GridSearchCV(svc, parameters)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  GridSearchCV(estimator=SVC(),\n",
      " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split2_test_score', ...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |      This attribute is not available if ``refit`` is a function.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  multimetric_ : bool\n",
      " |      Whether or not the scorers compute several metrics.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  See Also\n",
      " |  ---------\n",
      " |  ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
      " |  train_test_split : Utility function to split the data into a development\n",
      " |      set usable for fitting a GridSearchCV instance and an evaluation set\n",
      " |      for its final evaluation.\n",
      " |  sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
      " |      loss function.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      " |      \n",
      " |      **fit_params : dict of str -> object\n",
      " |          Parameters passed to the ``fit`` method of the estimator\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Returns the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |  \n",
      " |  score_samples(self, X)\n",
      " |      Call score_samples on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``score_samples``.\n",
      " |      \n",
      " |      .. versionadded:: 0.24\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements\n",
      " |          of the underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,)\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |  \n",
      " |  n_features_in_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "(398, 30) (398,) (171, 30) (171,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.001, 0.01, 1, 100.0, 1000.0],\n",
       "                         'gamma': [0.0001, 0.001, 0.1, 1],\n",
       "                         'kernel': ['linear', 'rbf']})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer_data = load_breast_cancer()\n",
    "print(type(breast_cancer_data))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_data.data, breast_cancer_data.target, test_size=0.30)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import SVC\n",
    "#Tuning: Model selection\n",
    "param_grid = {\n",
    "               'C': [1e-3, 1e-2, 1, 1e2, 1e3],\n",
    "              'gamma': [0.0001, 0.001, 0.1, 1], \n",
    "               'kernel': ['linear', 'rbf'],\n",
    "             }\n",
    "\n",
    "clf1 = GridSearchCV( SVC(), param_grid)\n",
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices shape of support vectors (32,)\n",
      "Dual coeffecients (1, 32)\n",
      "Number of support vectors per each class: [17 15]\n"
     ]
    }
   ],
   "source": [
    "print(\"Indices shape of support vectors\", clf1.best_estimator_.support_.shape)\n",
    "print(\"Dual coeffecients\", clf1.best_estimator_.dual_coef_.shape)\n",
    "print(\"Number of support vectors per each class:\", clf1.best_estimator_.n_support_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Indices of support vectors [ 21  89  95  96 136 149 159 167 194 201 241 249 284 346 366 384 396  54\n",
      " 141 146 154 155 174 240 244 257 266 308 309 340 376 391]\n",
      "\n",
      "Dual coeffecients [-100.         -100.          -10.03456576 -100.         -100.\n",
      " -100.         -100.          -50.73995457  -10.67618679 -100.\n",
      "   -1.60520427 -100.          -11.9827846  -100.          -81.30596273\n",
      "  -50.02252599 -100.          100.          100.           44.78607009\n",
      "  100.          100.            9.98173968  100.           45.60132648\n",
      "  100.          100.          100.          100.           15.99804845\n",
      "  100.          100.        ]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nIndices of support vectors\", clf1.best_estimator_.support_)\n",
    "print(\"\\nDual coeffecients\", clf1.best_estimator_.dual_coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3955059330328368e-11"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.best_estimator_.dual_coef_[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coeffecients (1, 30)\n",
      "\n",
      "Coeffecients [ 1.95460067e+01  4.73604472e+00 -3.47572993e+00  3.19151432e-02\n",
      " -1.19059097e+01 -4.57890381e+00 -2.06759918e+01 -2.14973329e+01\n",
      " -1.56807546e+01 -2.07670430e-01 -6.32230788e-01  2.61106577e+01\n",
      "  1.80905461e+01 -2.57548398e+00 -2.40516005e+00  3.77375719e+00\n",
      "  7.74884703e-02 -3.65337142e+00 -3.44302896e+00  5.71447173e-01\n",
      "  2.87039596e+00 -6.58107152e+00 -1.03763074e+00  5.38692445e-02\n",
      " -1.82033227e+01  1.89074431e+01 -2.32645437e+01 -3.53329163e+01\n",
      " -2.84736384e+01  4.55082294e-01]\n",
      "\n",
      "Bias Coeffecient 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCoeffecients\", clf1.best_estimator_.coef_.shape)\n",
    "print(\"\\nCoeffecients\", clf1.best_estimator_.coef_[0])\n",
    "print(\"\\nBias Coeffecient\", clf1.best_estimator_.coef0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.88078880e-03, 4.26893234e-03, 2.14557648e-03, 4.68382835e-03,\n",
       "        0.00000000e+00, 5.64951897e-03, 2.00390816e-03, 5.21998405e-03,\n",
       "        7.39235878e-03, 2.26073265e-03, 7.91015625e-03, 3.59902382e-03,\n",
       "        6.39934540e-03, 5.53874969e-03, 6.00643158e-03, 5.59906960e-03,\n",
       "        3.37525129e-01, 1.73482895e-03, 3.36556244e-01, 5.83481789e-03,\n",
       "        3.37256479e-01, 9.47785378e-03, 3.38104820e-01, 6.25042915e-03,\n",
       "        3.27417355e+00, 0.00000000e+00, 3.33741689e+00, 2.61473656e-03,\n",
       "        3.35169544e+00, 3.12523842e-03, 3.32543736e+00, 8.25505257e-03,\n",
       "        3.31204877e+00, 2.14076042e-03, 3.34688802e+00, 5.16195297e-03,\n",
       "        3.35064244e+00, 8.26721191e-03, 3.35042300e+00, 6.34064674e-03]),\n",
       " 'std_fit_time': array([1.92115294e-03, 5.69598171e-03, 2.70298347e-04, 5.74356240e-03,\n",
       "        0.00000000e+00, 6.98653904e-03, 2.70127303e-05, 3.73613078e-04,\n",
       "        7.81995807e-03, 1.20243146e-03, 5.19905341e-03, 4.80481753e-04,\n",
       "        2.24640890e-03, 5.11159701e-04, 2.44716449e-03, 4.83817046e-04,\n",
       "        2.08349143e-01, 1.39086107e-03, 2.01986034e-01, 7.17656990e-03,\n",
       "        2.01676870e-01, 7.74035003e-03, 2.01682155e-01, 7.65518109e-03,\n",
       "        2.39070930e+00, 0.00000000e+00, 2.46618141e+00, 2.16999972e-03,\n",
       "        2.46499387e+00, 6.25047684e-03, 2.43158127e+00, 5.84680208e-03,\n",
       "        1.91836412e+00, 1.77609016e-03, 2.00492177e+00, 6.03999456e-03,\n",
       "        2.00510327e+00, 7.05336461e-03, 2.00797702e+00, 6.07885770e-03]),\n",
       " 'mean_score_time': array([6.49261475e-04, 7.99417496e-04, 0.00000000e+00, 1.99365616e-04,\n",
       "        0.00000000e+00, 3.52411270e-03, 3.96871567e-04, 2.89912224e-03,\n",
       "        0.00000000e+00, 9.92870331e-04, 4.12797928e-04, 1.99913979e-03,\n",
       "        4.01973724e-04, 2.74562836e-03, 3.98492813e-04, 2.61197090e-03,\n",
       "        2.64644623e-05, 4.66775894e-04, 2.11858749e-04, 5.09834290e-04,\n",
       "        1.07574463e-04, 0.00000000e+00, 2.00271606e-04, 3.12490463e-03,\n",
       "        0.00000000e+00, 3.12638283e-03, 3.23729515e-03, 8.54682922e-04,\n",
       "        4.04167175e-04, 6.32739067e-03, 0.00000000e+00, 9.27257538e-04,\n",
       "        0.00000000e+00, 1.12228394e-03, 0.00000000e+00, 6.95896149e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.12514305e-03]),\n",
       " 'std_score_time': array([7.50715170e-04, 7.61581091e-04, 0.00000000e+00, 3.98731232e-04,\n",
       "        0.00000000e+00, 6.09843540e-03, 4.86089623e-04, 1.78110800e-04,\n",
       "        0.00000000e+00, 8.93099508e-04, 5.05572196e-04, 3.58485148e-05,\n",
       "        4.92332091e-04, 4.01843096e-04, 4.88069645e-04, 4.97091122e-04,\n",
       "        5.29289246e-05, 5.72232413e-04, 4.23717499e-04, 1.01966858e-03,\n",
       "        2.15148926e-04, 0.00000000e+00, 4.00543213e-04, 6.24980927e-03,\n",
       "        0.00000000e+00, 6.25276566e-03, 6.19790040e-03, 8.40286783e-04,\n",
       "        4.95018418e-04, 5.86793808e-03, 0.00000000e+00, 9.11453958e-04,\n",
       "        0.00000000e+00, 2.24456787e-03, 0.00000000e+00, 9.30847316e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.25028610e-03]),\n",
       " 'param_C': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 100.0, 100.0, 100.0, 100.0, 100.0,\n",
       "                    100.0, 100.0, 100.0, 1000.0, 1000.0, 1000.0, 1000.0,\n",
       "                    1000.0, 1000.0, 1000.0, 1000.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.1, 0.1, 1, 1, 0.0001,\n",
       "                    0.0001, 0.001, 0.001, 0.1, 0.1, 1, 1, 0.0001, 0.0001,\n",
       "                    0.001, 0.001, 0.1, 0.1, 1, 1, 0.0001, 0.0001, 0.001,\n",
       "                    0.001, 0.1, 0.1, 1, 1, 0.0001, 0.0001, 0.001, 0.001,\n",
       "                    0.1, 0.1, 1, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.001, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 0.001, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 0.001, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 0.001, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.001, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 0.001, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 0.001, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 0.001, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 100.0, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 100.0, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 100.0, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 100.0, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 100.0, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 100.0, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 100.0, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1000.0, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 1000.0, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1000.0, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 1000.0, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1000.0, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 1000.0, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1000.0, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 1000.0, 'gamma': 1, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.95  , 0.6125, 0.95  , 0.6125, 0.95  , 0.6125, 0.95  , 0.6125,\n",
       "        0.9375, 0.6125, 0.9375, 0.6125, 0.9375, 0.6125, 0.9375, 0.6125,\n",
       "        0.9625, 0.95  , 0.9625, 0.925 , 0.9625, 0.6125, 0.9625, 0.6125,\n",
       "        0.9875, 0.9125, 0.9875, 0.9125, 0.9875, 0.6125, 0.9875, 0.6125,\n",
       "        0.9875, 0.9   , 0.9875, 0.9125, 0.9875, 0.6125, 0.9875, 0.6125]),\n",
       " 'split1_test_score': array([0.9   , 0.6125, 0.9   , 0.6125, 0.9   , 0.6125, 0.9   , 0.6125,\n",
       "        0.9   , 0.6125, 0.9   , 0.6125, 0.9   , 0.6125, 0.9   , 0.6125,\n",
       "        0.925 , 0.8875, 0.925 , 0.825 , 0.925 , 0.6125, 0.925 , 0.6125,\n",
       "        0.95  , 0.9125, 0.95  , 0.8125, 0.95  , 0.6125, 0.95  , 0.6125,\n",
       "        0.95  , 0.9125, 0.95  , 0.8125, 0.95  , 0.6125, 0.95  , 0.6125]),\n",
       " 'split2_test_score': array([0.9125, 0.6125, 0.9125, 0.6125, 0.9125, 0.6125, 0.9125, 0.6125,\n",
       "        0.95  , 0.6125, 0.95  , 0.6125, 0.95  , 0.6125, 0.95  , 0.6125,\n",
       "        0.9375, 0.925 , 0.9375, 0.9375, 0.9375, 0.6125, 0.9375, 0.6125,\n",
       "        0.95  , 0.95  , 0.95  , 0.9375, 0.95  , 0.6125, 0.95  , 0.6125,\n",
       "        0.95  , 0.9375, 0.95  , 0.9375, 0.95  , 0.6125, 0.95  , 0.6125]),\n",
       " 'split3_test_score': array([0.94936709, 0.62025316, 0.94936709, 0.62025316, 0.94936709,\n",
       "        0.62025316, 0.94936709, 0.62025316, 0.94936709, 0.62025316,\n",
       "        0.94936709, 0.62025316, 0.94936709, 0.62025316, 0.94936709,\n",
       "        0.62025316, 0.94936709, 0.92405063, 0.94936709, 0.93670886,\n",
       "        0.94936709, 0.62025316, 0.94936709, 0.62025316, 0.94936709,\n",
       "        0.96202532, 0.94936709, 0.86075949, 0.94936709, 0.62025316,\n",
       "        0.94936709, 0.62025316, 0.94936709, 0.94936709, 0.94936709,\n",
       "        0.86075949, 0.94936709, 0.62025316, 0.94936709, 0.62025316]),\n",
       " 'split4_test_score': array([0.96202532, 0.60759494, 0.96202532, 0.60759494, 0.96202532,\n",
       "        0.60759494, 0.96202532, 0.60759494, 0.97468354, 0.60759494,\n",
       "        0.97468354, 0.60759494, 0.97468354, 0.60759494, 0.97468354,\n",
       "        0.60759494, 0.96202532, 0.92405063, 0.96202532, 0.92405063,\n",
       "        0.96202532, 0.60759494, 0.96202532, 0.60759494, 0.94936709,\n",
       "        0.92405063, 0.94936709, 0.92405063, 0.94936709, 0.60759494,\n",
       "        0.94936709, 0.60759494, 0.94936709, 0.92405063, 0.94936709,\n",
       "        0.92405063, 0.94936709, 0.60759494, 0.94936709, 0.60759494]),\n",
       " 'mean_test_score': array([0.93477848, 0.61306962, 0.93477848, 0.61306962, 0.93477848,\n",
       "        0.61306962, 0.93477848, 0.61306962, 0.94231013, 0.61306962,\n",
       "        0.94231013, 0.61306962, 0.94231013, 0.61306962, 0.94231013,\n",
       "        0.61306962, 0.94727848, 0.92212025, 0.94727848, 0.9096519 ,\n",
       "        0.94727848, 0.61306962, 0.94727848, 0.61306962, 0.95724684,\n",
       "        0.93221519, 0.95724684, 0.88946203, 0.95724684, 0.61306962,\n",
       "        0.95724684, 0.61306962, 0.95724684, 0.92468354, 0.95724684,\n",
       "        0.88946203, 0.95724684, 0.61306962, 0.95724684, 0.61306962]),\n",
       " 'std_test_score': array([0.02405321, 0.00406322, 0.02405321, 0.00406322, 0.02405321,\n",
       "        0.00406322, 0.02405321, 0.00406322, 0.02437317, 0.00406322,\n",
       "        0.02437317, 0.00406322, 0.02437317, 0.00406322, 0.02437317,\n",
       "        0.00406322, 0.01446012, 0.0199579 , 0.01446012, 0.04269995,\n",
       "        0.01446012, 0.00406322, 0.01446012, 0.00406322, 0.01512923,\n",
       "        0.02024342, 0.01512923, 0.04643653, 0.01512923, 0.00406322,\n",
       "        0.01512923, 0.00406322, 0.01512923, 0.01750232, 0.01512923,\n",
       "        0.04643653, 0.01512923, 0.00406322, 0.01512923, 0.00406322]),\n",
       " 'rank_test_score': array([17, 27, 17, 27, 17, 27, 17, 27, 13, 27, 13, 27, 13, 27, 13, 27,  9,\n",
       "        23,  9, 24,  9, 27,  9, 27,  1, 21,  1, 25,  1, 27,  1, 27,  1, 22,\n",
       "         1, 25,  1, 27,  1, 27])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercises\n",
    "# 1. Run SVM on wines dataset and find the best parameters using Gridserach (try acccuracy upto 99%)\n",
    "# try with various C values\n",
    "# try with various kernels(linear, poly, rbf) and gamma parameters\n",
    "\n",
    "# 2. Run SVM on iris data set and find the best parameters using Grid serach (try acccuracy upto 99%)\n",
    "\n",
    "# 3. Run SVM on breast_cancer dataset using Grdiserach\n",
    "# before running please select best K features using sklearn.feature_selection.SelectKBest()\n",
    "# or select features using forward/backward using sklearn.feature_selection.SequentialFeatureSelector()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
